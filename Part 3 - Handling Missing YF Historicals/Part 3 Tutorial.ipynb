{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Missing EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hxrxS-7rOBv3l3J6C-CtHi_OcBRYHu6o",
      "authorship_tag": "ABX9TyN4VCUuCZl5XpEPBR+Bvm80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muchcreative/15Yr-Free-Historical-Data-and-Cleaning/blob/main/Missing_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_bhzTk-xvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5df850f-1815-473c-a18b-87d8ff5f08ff"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import math\n",
        "\n",
        "import copy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import importlib\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/April/pipelines')\n",
        "\n",
        "import loaders\n",
        "import filters\n",
        "import interpolators\n",
        "\n",
        "print(\"Importing Complete\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Importing Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI1U10NAz68x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3fa6ff-edc5-4ef8-8206-22e7772ba6ad"
      },
      "source": [
        "changes_in_sp500 = loaders.load_changes_in_sp500()\n",
        "iex_sp500_constituents = loaders.load_iex_sp500_constituents()\n",
        "historicals = loaders.load_sp500_historicals(iex_sp500_constituents, '5Yhistoricals')\n",
        "print('Data Loaded')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc7poEryyAVs"
      },
      "source": [
        "#Filter out incomplete data and interpolate the rest when avaliable\n",
        "#For now, don't directly edit the database. Just run when needed. Incase you want to do changes to your interpolator or filters\n",
        "ticker_with_full_data = 'AAL'\n",
        "tolerance = 0.05\n",
        "\n",
        "missing_historicals, removed_tickers = filters.find_tickers_that_require_interpolation(historicals, \n",
        "                                            changes_in_sp500, \n",
        "                                            ticker_with_full_data,\n",
        "                                            tolerance)\n",
        "\n",
        "historicals = filters.delete_removed_tickers_from_historicals(historicals, removed_tickers)\n",
        "\n",
        "known_interpolation_data, unknown_interpolation_data = interpolators.prep_data_for_interpolation(historicals, missing_historicals)\n",
        "\n",
        "historicals, solved_interpolated_data = interpolators.linearly_interpolate_to_historicals_df(known_interpolation_data, \n",
        "                                                unknown_interpolation_data, \n",
        "                                                historicals)\n",
        "\n",
        "historicals = interpolators.insert_interpolated_dates_into_historicals(historicals, solved_interpolated_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vN5eSrBZIAM"
      },
      "source": [
        "#Length of missing data\n",
        "def find_amount_of_missing_data_for_each_ticker(backtest_missing_historicals):\n",
        "  amount_of_missing_data_for_each_ticker = []\n",
        "  for missing_dates in backtest_missing_historicals.values():\n",
        "    amount_of_missing_data_for_each_ticker.append(len(missing_dates))\n",
        "  return amount_of_missing_data_for_each_ticker\n",
        "\n",
        "def find_days_spent_in_the_sp500(missing_data_summary, historicals, date_range_for_tickers_in_sp500):\n",
        "  days_spent_in_the_sp500 = []\n",
        "  for ticker in missing_data_summary['Ticker']:\n",
        "    days_spent_in_the_sp500.append(len(historicals['AAL'].loc[date_range_for_tickers_in_sp500[ticker][0]:date_range_for_tickers_in_sp500[ticker][1]]))\n",
        "  return days_spent_in_the_sp500\n",
        "\n",
        "def remove_tickers_not_in_sp500(missing_data_summary):\n",
        "  missing_data_summary = missing_data_summary[missing_data_summary['Days Spent in SP500'] != 0]\n",
        "  return missing_data_summary\n",
        "\n",
        "#For interval sensitivity analysis\n",
        "def find_missing_data_at_different_intervals(tickers_with_missing_data, interval_size):\n",
        "  missing_data_at_each_interval = [[i,0] for i in range(0, 1300, interval_size)] #1300 to ensure it gets all missing data at 1258 days\n",
        "  for missing_days_amount in tickers_with_missing_data['Missing Days Amount']:\n",
        "    interval = math.floor(missing_days_amount / interval_size)\n",
        "    missing_data_at_each_interval[interval][1] += 1\n",
        "  return missing_data_at_each_interval\n",
        "\n",
        "# Find Tickers with Missing Data #\n",
        "missing_data_summary = pd.DataFrame(historicals.keys(), columns=['Ticker'])\n",
        "missing_data_summary['Missing Dates'] = pd.Series(historicals.values(), dtype='object')\n",
        "missing_data_summary['Missing Days Amount'] = pd.Series(find_amount_of_missing_data_for_each_ticker(historicals), dtype = 'int64')\n",
        "missing_data_summary['Days Spent in SP500'] = pd.Series(find_days_spent_in_the_sp500(missing_data_summary, historicals, changes_in_sp500), dtype = 'int64')\n",
        "missing_data_summary = remove_tickers_not_in_sp500(missing_data_summary)\n",
        "\n",
        "# Find Cumulative Sum of Missing Data if Allotted Tickers Increase #\n",
        "missing_data_summary = missing_data_summary.sort_values('Missing Days Amount', ascending = True)\n",
        "missing_data_summary = missing_data_summary.reset_index(drop = True)\n",
        "missing_data_summary['Cumulative Sum of Missing Days'] = missing_data_summary['Missing Days Amount'].cumsum()\n",
        "\n",
        "# Find Missing Data for Different Intervals #\n",
        "interval_size = 50\n",
        "missing_data_at_each_interval = find_missing_data_at_different_intervals(missing_data_summary, interval_size)\n",
        "missing_data_at_each_interval_columns = ['Missing Days Amount', 'Tickers Amount']\n",
        "missing_data_at_each_interval = pd.DataFrame(missing_data_at_each_interval, columns = missing_data_at_each_interval_columns)\n",
        "\n",
        "# Plot Both Missing Data at Each Interval and Cum Sum of Missing Data\n",
        "fig, ax = plt.subplots(1, 2, figsize = (30,10))\n",
        "interval_plot = sns.barplot(x = 'Missing Days Amount', y = 'Tickers Amount', data = missing_data_at_each_interval, ax = ax[0])\n",
        "interval_plot.set_title('Missing Days and Ticker Amount for each Interval')\n",
        "cum_sum_plot = sns.lineplot(x = missing_data_summary.index, y = 'Cumulative Sum of Missing Days', data = missing_data_summary, ax=ax[1])\n",
        "cum_sum_plot.set_title('Missing Days as Allotted Tickers Increase')\n",
        "cum_sum_plot.set_xlabel('Ticker Amount')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4x6RYZ-oGQT"
      },
      "source": [
        "#Sort by average market cap\n",
        "#Sort by average realized volatility\n",
        "#Sort by implied volaility\n",
        "#Sort versus volatility realized and implied between months"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPUWOVerEBBr"
      },
      "source": [
        "## Introspective EDA and Internal Correlatiosn ##\n",
        "#Triple Correlation Between Stocks \n",
        "\n",
        "#Get 15 year data now\n",
        "#Add VIX\n",
        "#Add SPY\n",
        "\n",
        "#Hpyothesize: Simalirly grouped insdustry and sectors have high kendall correlations and may be able to utilize similar trading strategies\n",
        "#Stocks of companies in the same industry will usually trade in the same direction, as their fundamentals are affected by market factors in the same way.\n",
        "\n",
        "#Check Skew of stocks, month to month movements?? HUH?\n",
        "#Model distribution and check for outliers and what dates those happened in\n",
        "#Skewer of earning dates gains / losses\n",
        "#Earning dates, and fundamentals, can you check revised earning estimates, priced in vs what is not priced in\n",
        "\n",
        "#Should try to understand some weakness of the model\n",
        "\n",
        "#SP500 Common Industries and Stock Correlations\n",
        "#SP500 Financials\n",
        "#SP500 Valuation Fundamentals\n",
        "#Company"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8u65mrmCGuN"
      },
      "source": [
        "## Interspective EDA and External Correlations ##\n",
        "\n",
        "#Indicators and Top Momentum Stocks\n",
        "#Indicators and Top Market Cap Stocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJP2mbOoDm9-"
      },
      "source": [
        "## Volatility EDA ##\n",
        "#Will need to pull vix from yahoo, can de-noise areas as well for future model ensembling\n",
        "\n",
        "#Correlation between indicators and realized volatility\n",
        "#Implied voltility from VIX and historical realized volatility, take a look at bollinger bands and average true range\n",
        "#Internal spikes and deviations from VIX, try de-noising (Wavelet Denoising or Moving Average Denosising)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnHifP5lp2h_"
      },
      "source": [
        "#Basic EDA and Fundamental Theory, Over long periods of time, companies will obtain their true valuation\n",
        "\n",
        "#Define what fundamentals you want\n",
        "#Fundamental valulations endpoint\n",
        "#Fundamental filling date and earning report date\n",
        "\n",
        "#Only EDA on current SP500 and every 5 years\n",
        "#Start EDA with current SP500\n",
        "\n",
        "#What will EDA look like?\n",
        "\n",
        "#Percentage of stocks that generated the top returns, graphed\n",
        "#How high volatility is\n",
        "#Compare growth metrics and volatility for the top companies\n",
        "#Beta of the stocks\n",
        "#Compare market cap\n",
        "#Compare frequency of volatility\n",
        "\n",
        "#1.\tPercentage gains for each stock in comparison to market cap\n",
        "#2.\tVolatility distribution of each stock\n",
        "#3.\tBeta, covariance, and variance compared to sp500 index and nasdaq"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
