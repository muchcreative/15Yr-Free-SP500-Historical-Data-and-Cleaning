{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2 Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj6aFRrEkc7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a5ba5a-d557-494a-cb52-02fa532e4107"
      },
      "source": [
        "#Install modules as needed\n",
        "%pip install yfinance #If you are using an ide use the python magic function \"%pip install\" to always get the latest version\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "print(\"Importing Complete\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.69)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.7.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Importing Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwIeixyhiEni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2481041e-8af4-48ba-88e5-725723c52f7c"
      },
      "source": [
        "#Let's bring in all the SP500 Consitutents we need to download off of Yahoo Finance, this is file we got from the Part 1 Tutorial, \n",
        "sp500_constituents_filepath = '/p2data/S&P500 Consitutents 20070101-20220116.json' #It has been placed in p2data for easy access\n",
        "\n",
        "with open(sp500_constituents_filepath, 'r') as f:\n",
        "  sp500_constituents = json.load(f)\n",
        "\n",
        "additional_tickers = ['SPY','DIA','QQQ','^VIX'] #You may add any additional tickers you want here thats no in the SP500\n",
        "\n",
        "tickers = sp500_constituents + additional_tickers\n",
        "print('We need to download {} tickers'.format(len(tickers))) #We see that there are 848 tickers we need to download"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to download 848 tickers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#848 is a lot of tickers and data. Let's slice our tickers list and choose to download 100 of them at a time\n",
        "#Start with slices [:100] --> [100:200] --> [200:300] or any amount of tickers you are comfortable with to download at a time\n",
        "#You can slice the tickers here then run all the code below to save them to the file format of your choice. \n",
        "#Then you can come back to this cell and select a new slice to download\n",
        "\n",
        "sliced_tickers = tickers[:100]\n",
        "print(sliced_tickers) #Print the tickers here to double check that they are different than the ones you just downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrv2LVXZbC8c",
        "outputId": "fb88da1a-078a-408e-f051-1ff2210b596f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'AABA', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABI', 'ABKFQ', 'ABMD', 'ABT', 'ACAS', 'ACN', 'ACS', 'ADBE', 'ADCT', 'ADI', 'ADM', 'ADP', 'ADS', 'ADSK', 'ADT', 'AEE', 'AEP', 'AES', 'AET', 'AFL', 'AGN', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'AKS', 'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'ALTR', 'ALXN', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMG', 'AMGN', 'AMP', 'AMT', 'AMZN', 'AN', 'ANDV', 'ANET', 'ANF', 'ANRZQ', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'APC', 'APCC', 'APD', 'APH', 'APOL', 'APTV', 'ARE', 'ARG', 'ARNC', 'ASH', 'ASN', 'AT', 'ATGE', 'ATI', 'ATO', 'ATVI', 'AV', 'AVB', 'AVGO', 'AVP', 'AVY', 'AW', 'AWK', 'AXP', 'AYE', 'AYI', 'AZO', 'BA', 'BAC', 'BAX', 'BBBY', 'BBT', 'BBWI', 'BBY', 'BC', 'BCR', 'BDK', 'BDX', 'BEAM', 'BEN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#With our ticker slice we can now download their historicals. Note that the YF modules is not a REST API. It works more similar to a web scraper.\n",
        "#We will also create two lists that will record which tickers were avaliable on YF and those that were not avaliable on YF\n",
        "#We will address the unavaliable tickers in the Part 3 Tutorial\n",
        "\n",
        "def download_yf_tickers(tickers, period='15y'): #You can take more than 15yrs here or specifiy a start_date and end_date\n",
        "  historicals = dict()\n",
        "  tickers_avaliable_on_yf = []\n",
        "  tickers_not_avaliable_on_yf = []\n",
        "\n",
        "  for ticker in tickers:\n",
        "    ticker_ref = yf.Ticker(ticker)\n",
        "    ticker_history = ticker_ref.history(period=period, \n",
        "                                        auto_adjust=True) #auto_adjust=True, to get adjusted OHLC\n",
        "\n",
        "    if ticker_history.empty: #Returns an empty DataFrame if the tickers YF history doesn't exist\n",
        "      tickers_not_avaliable_on_yf.append(ticker)\n",
        "    else: \n",
        "      historicals[ticker] = ticker_history\n",
        "      tickers_avaliable_on_yf.append(ticker)\n",
        "  return (historicals, tickers_avaliable_on_yf, tickers_not_avaliable_on_yf)\n",
        "\n",
        "historicals, tickers_avaliable_on_yf, tickers_not_avaliable_on_yf = download_yf_tickers(sliced_tickers)"
      ],
      "metadata": {
        "id": "IQ_YjgnwycMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7225667b-9d23-4bb9-912a-15ca31756e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- AABA: No data found, symbol may be delisted\n",
            "- ABI: No data found for this date range, symbol may be delisted\n",
            "- ABKFQ: No data found, symbol may be delisted\n",
            "- ACAS: No data found for this date range, symbol may be delisted\n",
            "- AGN: No data found, symbol may be delisted\n",
            "- AKS: No data found, symbol may be delisted\n",
            "- ALXN: No data found, symbol may be delisted\n",
            "- ANRZQ: No data found for this date range, symbol may be delisted\n",
            "- APC: No data found, symbol may be delisted\n",
            "- APCC: No data found for this date range, symbol may be delisted\n",
            "- APOL: No data found for this date range, symbol may be delisted\n",
            "- ARG: No data found for this date range, symbol may be delisted\n",
            "- AT: No data found, symbol may be delisted\n",
            "- AV: No data found for this date range, symbol may be delisted\n",
            "- AVP: No data found, symbol may be delisted\n",
            "- AW: No data found for this date range, symbol may be delisted\n",
            "- BBT: No data found, symbol may be delisted\n",
            "- BCR: No data found for this date range, symbol may be delisted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep track of the tickers that were avaliable on yf and those that weren't, we will save it in p2outputs in the logs folder\n",
        "def record_attendance_of_tickers_to_json(tickers_to_sort, \n",
        "                                        filepath,\n",
        "                                        status):\n",
        "  log_filepath = f'{filepath}/{status}_yf_tickers.json'\n",
        "  log_file = Path(log_filepath) #To check if the file already exists, if so we will extend and overwrtie the list\n",
        "  if log_file.is_file():\n",
        "    with open(log_filepath, 'r+', encoding='utf-8') as f:\n",
        "      updated_tickers_lst = json.load(f)\n",
        "      updated_tickers_lst.extend(tickers_to_sort)\n",
        "      f.seek(0)\n",
        "      json.dump(updated_tickers_lst, f, ensure_ascii=False, indent=4)\n",
        "  else: #If file does not exist, we will create one and dump the tickers_lst into it\n",
        "    with open(log_filepath , 'w', encoding='utf-8') as f:\n",
        "      json.dump(tickers_to_sort, f, ensure_ascii=False, indent=4)\n",
        "  print('{0} tickers have been logged to {0} tickers list'.format(status))\n",
        "  return\n",
        "\n",
        "logs_filepath = '/p2outputs/logs'\n",
        "record_attendance_of_tickers_to_json(tickers_avaliable_on_yf,\n",
        "                                     logs_filepath,\n",
        "                                     status='avaliable')\n",
        "record_attendance_of_tickers_to_json(tickers_not_avaliable_on_yf,\n",
        "                                     logs_filepath,\n",
        "                                     status='missing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTudJ3dwYqqS",
        "outputId": "e49c494e-f7ce-4070-8caf-1c610b6ef7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avaliable tickers have been logged to avaliable tickers list\n",
            "missing tickers have been logged to missing tickers list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here you can choose which format you want to save your historicals as\n",
        "#You can use pd.hdfstore to store your historicals in a pandas format but it will require different formatting. \n",
        "#Currently hdf5 are saved to accommodate loading as numpys\n",
        "\n",
        "def format_historicals_to_csv(historicals):\n",
        "  '''\n",
        "  Description:\n",
        "    - Remove dividends and stock splits, as adjusted OHLC will already consider them\n",
        "  Returns:\n",
        "    - Formatted historicals for a CSV file\n",
        "  '''\n",
        "  for ticker in historicals:\n",
        "    historicals[ticker] = historicals[ticker].drop(['Dividends', 'Stock Splits'], axis='columns')\n",
        "    historicals[ticker] = historicals[ticker].reset_index()\n",
        "  print('Finished formatting historicals as csv format')\n",
        "  return historicals\n",
        "\n",
        "def format_historicals_to_hdf5(historicals):\n",
        "  '''\n",
        "  Description:\n",
        "    - Remove dividends and stock splits, as adjusted OHLC will already consider them\n",
        "    - Change datetime to timestamps for HDF5 as HDF5 does not accept datetimes\n",
        "  Returns:\n",
        "    - Formatted historicals for an HDF5 file\n",
        "  '''\n",
        "  for ticker in historicals:\n",
        "    historicals[ticker] = historicals[ticker].drop(['Dividends', 'Stock Splits'], axis='columns')\n",
        "    historicals[ticker] = historicals[ticker].reset_index()\n",
        "    historicals[ticker]['Date'] = historicals[ticker]['Date'].apply(lambda x: x.timestamp())\n",
        "  print('Finished formatting historicals as hdf5 format')\n",
        "  return historicals\n",
        "\n",
        "hdf5_historicals = format_historicals_to_hdf5(historicals)"
      ],
      "metadata": {
        "id": "vzGIFqTuW0IS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd7dd67-a42d-47a6-a052-4665b0ee63d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished formatting historicals as hdf5 format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save your historicals to a filepath of your choice\n",
        "def save_historicals_to_csv(historicals, filepath):\n",
        "  for ticker in historicals:\n",
        "    csv_filepath = f'{filepath}/{ticker}.csv'\n",
        "    historicals[ticker].to_csv(csv_filepath)\n",
        "    print('Ticker {} Saved as CSV'.format(ticker))\n",
        "  print('All Tickers Have Been Saved')\n",
        "\n",
        "def save_historicals_to_hdf5(historicals, filepath):\n",
        "  for ticker in historicals:\n",
        "    hdf5_filepath = f'{filepath}/{ticker}.hdf5'\n",
        "    with h5py.File(hdf5_filepath, 'w') as f:\n",
        "      history = f.create_group('historicals')\n",
        "      history.create_dataset(name='15Y', data=historicals[ticker], compression='gzip')\n",
        "    print('Saved {} as HDF5'.format(ticker))\n",
        "\n",
        "historicals_filepath = '/p2outputs'\n",
        "save_historicals_to_hdf5(hdf5_historicals, historicals_filepath)"
      ],
      "metadata": {
        "id": "rBv2YmScVD6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c0786b-d719-4a03-95a8-09382aa8ca5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved A as HDF5\n",
            "Saved AAL as HDF5\n",
            "Saved AAP as HDF5\n",
            "Saved AAPL as HDF5\n",
            "Saved ABBV as HDF5\n",
            "Saved ABC as HDF5\n",
            "Saved ABMD as HDF5\n",
            "Saved ABT as HDF5\n",
            "Saved ACN as HDF5\n",
            "Saved ACS as HDF5\n",
            "Saved ADBE as HDF5\n",
            "Saved ADCT as HDF5\n",
            "Saved ADI as HDF5\n",
            "Saved ADM as HDF5\n",
            "Saved ADP as HDF5\n",
            "Saved ADS as HDF5\n",
            "Saved ADSK as HDF5\n",
            "Saved ADT as HDF5\n",
            "Saved AEE as HDF5\n",
            "Saved AEP as HDF5\n",
            "Saved AES as HDF5\n",
            "Saved AET as HDF5\n",
            "Saved AFL as HDF5\n",
            "Saved AIG as HDF5\n",
            "Saved AIV as HDF5\n",
            "Saved AIZ as HDF5\n",
            "Saved AJG as HDF5\n",
            "Saved AKAM as HDF5\n",
            "Saved ALB as HDF5\n",
            "Saved ALGN as HDF5\n",
            "Saved ALK as HDF5\n",
            "Saved ALL as HDF5\n",
            "Saved ALLE as HDF5\n",
            "Saved ALTR as HDF5\n",
            "Saved AMAT as HDF5\n",
            "Saved AMCR as HDF5\n",
            "Saved AMD as HDF5\n",
            "Saved AME as HDF5\n",
            "Saved AMG as HDF5\n",
            "Saved AMGN as HDF5\n",
            "Saved AMP as HDF5\n",
            "Saved AMT as HDF5\n",
            "Saved AMZN as HDF5\n",
            "Saved AN as HDF5\n",
            "Saved ANDV as HDF5\n",
            "Saved ANET as HDF5\n",
            "Saved ANF as HDF5\n",
            "Saved ANSS as HDF5\n",
            "Saved ANTM as HDF5\n",
            "Saved AON as HDF5\n",
            "Saved AOS as HDF5\n",
            "Saved APA as HDF5\n",
            "Saved APD as HDF5\n",
            "Saved APH as HDF5\n",
            "Saved APTV as HDF5\n",
            "Saved ARE as HDF5\n",
            "Saved ARNC as HDF5\n",
            "Saved ASH as HDF5\n",
            "Saved ASN as HDF5\n",
            "Saved ATGE as HDF5\n",
            "Saved ATI as HDF5\n",
            "Saved ATO as HDF5\n",
            "Saved ATVI as HDF5\n",
            "Saved AVB as HDF5\n",
            "Saved AVGO as HDF5\n",
            "Saved AVY as HDF5\n",
            "Saved AWK as HDF5\n",
            "Saved AXP as HDF5\n",
            "Saved AYE as HDF5\n",
            "Saved AYI as HDF5\n",
            "Saved AZO as HDF5\n",
            "Saved BA as HDF5\n",
            "Saved BAC as HDF5\n",
            "Saved BAX as HDF5\n",
            "Saved BBBY as HDF5\n",
            "Saved BBWI as HDF5\n",
            "Saved BBY as HDF5\n",
            "Saved BC as HDF5\n",
            "Saved BDK as HDF5\n",
            "Saved BDX as HDF5\n",
            "Saved BEAM as HDF5\n",
            "Saved BEN as HDF5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if all the tickers were saved succesfully as the file format of your choice, please specifiy in the 'save_type' keyword\n",
        "def check_if_tickers_were_saved_successfully(tickers_avaliable_on_yf, \n",
        "                                            filepath,\n",
        "                                            save_type='hdf5'):\n",
        "  assert save_type in ['csv', 'hdf5'], 'Save type must be \"csv\" or \"hdf5\"'\n",
        "\n",
        "  tickers_not_saved = []\n",
        "  for ticker in tickers_avaliable_on_yf:\n",
        "    ticker_filepath = f'{filepath}/{ticker}.{save_type}'\n",
        "    ticker_file = Path(ticker_filepath)\n",
        "    if ticker_file.is_file():\n",
        "      pass\n",
        "    else:\n",
        "      print(\"{} is missing\".format(ticker))\n",
        "      tickers_not_saved.append(ticker)\n",
        "  return tickers_not_saved\n",
        "\n",
        "tickers_not_saved = check_if_tickers_saved_successfully(tickers_avaliable_on_yf, \n",
        "                                                        historicals_filepath,\n",
        "                                                        save_type='hdf5') #Change to csv or hdf5 depending on the format you used\n",
        "print('Tickers NOT saved successfully were {}'.format(tickers_not_saved))"
      ],
      "metadata": {
        "id": "8VyfjGzlaNgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff0a387-052d-48af-fc7f-d6e5a36c4f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tickers NOT saved successfully were []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Reference: How to load your database to memory"
      ],
      "metadata": {
        "id": "z3B-AImcjGH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For reference on how to load your database as a pandas dataframe, you will need your sp500_constituents list\n",
        "#There is no need to run this if you are still downloading all your historicals from Yahoo Finance\n",
        "\n",
        "def load_csv_tickers_as_pd_historicals(tickers, filepath):\n",
        "  historicals = dict()\n",
        "  '''\n",
        "    Description:\n",
        "      - Takes tickers as a list ['A', 'AAPL', 'AMZN']\n",
        "      - Formats CSV with pandas \"pd.read_csv\"\n",
        "    Returns:\n",
        "      - Historicals dict() containing formatted pandas DataFrames with tickers as keys\n",
        "  '''\n",
        "  for ticker in tickers:\n",
        "    csv_filepath = f'{filepath}/{ticker}.csv'\n",
        "    dataset = pd.read_csv(csv_filepath, index_col='Date')\n",
        "    historicals[ticker] = dataset\n",
        "  return historicals\n",
        "\n",
        "def load_hdf5_tickers_as_pd_historicals(tickers, filepath):\n",
        "  historicals = dict()\n",
        "  columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
        "  \n",
        "  for ticker in tickers:\n",
        "    hdf5_filepath = f'{filepath}/{ticker}.hdf5'\n",
        "    with h5py.File(hdf5_filepath, 'r') as f:\n",
        "      group = f['historicals']\n",
        "      data = group['15Y'][()]\n",
        "      \n",
        "    dataset = pd.DataFrame(data=data, columns=columns)\n",
        "    dataset['Date'] = pd.to_datetime(dataset['Date'], unit='s')\n",
        "    dataset = dataset.set_index('Date')\n",
        "    historicals[ticker] = dataset\n",
        "  return historicals\n",
        "\n",
        "historicals = load_hdf5_tickers_as_pd_historicals(sp500_constituents, historicals_filepath)"
      ],
      "metadata": {
        "id": "PCgJggrq4Bf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}