{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part 2 Tutorial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOPhETXKWUU/TfPvxAYjZkx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"qj6aFRrEkc7m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643338067198,"user_tz":420,"elapsed":3474,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"outputId":"a9ca028c-1f79-44d6-d63a-248bc3de3eb9"},"source":["import pandas as pd\n","import h5py\n","from pathlib import Path\n","import json\n","\n","%pip install yfinance  # If you are using an ide use the python magic function \"%pip install\" to always get the latest version\n","import yfinance as yf\n","\n","print(\"Importing Complete\") "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.69)\n","Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.7.1)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n","Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.10)\n","Importing Complete\n"]}]},{"cell_type":"code","metadata":{"id":"GwIeixyhiEni","executionInfo":{"status":"ok","timestamp":1642736771879,"user_tz":420,"elapsed":166,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2481041e-8af4-48ba-88e5-725723c52f7c"},"source":["# Let's bring in all the SP500 Consitutents we need to download off of Yahoo Finance, this is file we got from the Part 1 Tutorial\n","\n","sp500_constituents_filepath = '/p2inputs/S&P500 Consitutents 20070101-20220116.json'  # It has been placed in p2inputs for easy access\n","\n","with open(sp500_constituents_filepath, 'r') as f:\n","  sp500_constituents = json.load(f)\n","\n","additional_tickers = ['SPY','DIA','QQQ','^VIX']  # You may add any additional tickers you want here thats no in the SP500\n","\n","tickers = sp500_constituents + additional_tickers\n","print(f'We need to download {len(tickers)} tickers')  # We see that there are 848 tickers we need to download"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We need to download 848 tickers\n"]}]},{"cell_type":"code","source":["# 848 is a lot of tickers and data. Let's slice our tickers list and choose to download 100 of them at a time\n","# Start with slices [:100] --> [100:200] --> [200:300] or any amount of tickers you are comfortable with to download at a time\n","# You can slice the tickers here then run all the code below to save them to the file format of your choice. \n","# Then you can come back to this cell and select a new slice to download\n","\n","sliced_tickers = tickers[:100]\n","print(sliced_tickers)  # Print the tickers here to double check that they are different than the ones you just downloaded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vrv2LVXZbC8c","executionInfo":{"status":"ok","timestamp":1642737451199,"user_tz":420,"elapsed":170,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"outputId":"fb88da1a-078a-408e-f051-1ff2210b596f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['A', 'AABA', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABI', 'ABKFQ', 'ABMD', 'ABT', 'ACAS', 'ACN', 'ACS', 'ADBE', 'ADCT', 'ADI', 'ADM', 'ADP', 'ADS', 'ADSK', 'ADT', 'AEE', 'AEP', 'AES', 'AET', 'AFL', 'AGN', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'AKS', 'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'ALTR', 'ALXN', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMG', 'AMGN', 'AMP', 'AMT', 'AMZN', 'AN', 'ANDV', 'ANET', 'ANF', 'ANRZQ', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'APC', 'APCC', 'APD', 'APH', 'APOL', 'APTV', 'ARE', 'ARG', 'ARNC', 'ASH', 'ASN', 'AT', 'ATGE', 'ATI', 'ATO', 'ATVI', 'AV', 'AVB', 'AVGO', 'AVP', 'AVY', 'AW', 'AWK', 'AXP', 'AYE', 'AYI', 'AZO', 'BA', 'BAC', 'BAX', 'BBBY', 'BBT', 'BBWI', 'BBY', 'BC', 'BCR', 'BDK', 'BDX', 'BEAM', 'BEN']\n"]}]},{"cell_type":"code","source":["# With our ticker slice we can now download their historicals. Note that the YF modules is not a REST API. It works more similar to a web scraper.\n","# We will also create two lists that will record which tickers were avaliable on YF and those that were not avaliable on YF\n","# We will address the unavaliable tickers in the Part 3 Tutorial\n","\n","def download_yf_tickers(tickers, start_date='2007-01-22', end_date='2022-01-19'):\n","  '''Downloads specified ticker data from Yahoo Finance.\n","\n","  Uses the yahoo finance module to downloaded the specified tickers' OHLC data\n","  for the given start and end date range. Along with the downloaded data,\n","  two lists are returned. If the ticker was not avaliable for download\n","  on yahoo finance or were not avaliable for the given date range, the returned\n","  lists will record which tickers were or were not avaliable from yahoo finance.\n","\n","  Args:\n","    tickers: list containing each ticker given as a string.\n","    start_date: str with format as 'year-month-day'. Defaults '2007-01-22'.\n","    end_date: str with format as 'year-month-day'. Defaults '2022-01-19'.\n","\n","  Returns:\n","    Historicals: dict with tickers as keys and OHLC data as values.\n","                 Each OHLC data is given as a pandas dataframe. \n","    tickers_avaliable_on_yf: list of tickers that were avaliable on yahooo finance.\n","    tickers_not_avaliable_on_yf: list of tickers that were not avaliable on yahoo finance.\n","  '''\n","\n","  historicals = dict()\n","  tickers_avaliable_on_yf = []\n","  tickers_not_avaliable_on_yf = []\n","\n","  for ticker in tickers:\n","    ticker_ref = yf.Ticker(ticker)\n","    ticker_history = ticker_ref.history(start_date=start_date, end_date=end_date, auto_adjust=True)  # Set auto_adjust=True to get adjusted OHLC data\n","\n","    if ticker_history.empty:  # Returns an empty DataFrame if the tickers YF history doesn't exist\n","      tickers_not_avaliable_on_yf.append(ticker)\n","    else: \n","      historicals[ticker] = ticker_history\n","      tickers_avaliable_on_yf.append(ticker)\n","  return (historicals, tickers_avaliable_on_yf, tickers_not_avaliable_on_yf)\n","\n","historicals, tickers_avaliable_on_yf, tickers_not_avaliable_on_yf = download_yf_tickers(sliced_tickers)"],"metadata":{"id":"IQ_YjgnwycMc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keep track of the tickers that were avaliable on yf and those that weren't, we will save it in p2outputs in the logs folder\n","\n","def log_availability_of_tickers_to_json(tickers, filepath, status):\n","  '''Saves which tickers were or were not avaliable on yahoo finance as a json file.\n","\n","  If the json file already exists because you are downloading data from multiple\n","  sources the tickers will be added to the json file if they don't already exist\n","  in the file.\n","  \n","  Args:\n","    tickers: list containing each ticker given as string.\n","    filepath: string of where to save the attendance log to.\n","    status: string of the status of the tickers if they were available or missing\n","            from yahoo finance. The status will determine the name to give to the\n","            json file. Typically used statuses are {'avaliable', 'missing'}.\n","\n","  Returns:\n","    None\n","  '''\n","\n","  log_filepath = f'{filepath}/{status}_yf_tickers.json'\n","  log_file = Path(log_filepath)  # To check if the file already exists, if so we will add the tickers to the list\n","  if log_file.is_file():\n","    with open(log_filepath, 'r+', encoding='utf-8') as f:\n","      previous_tickers = json.load(f)\n","      previous_tickers.extend(tickers)\n","      updated_tickers = sorted(set(previous_tickers))\n","      f.seek(0)\n","      json.dump(updated_tickers, f, ensure_ascii=False, indent=4)\n","  else:  # If file does not exist, we will create one and dump the tickers list into it\n","    with open(log_filepath , 'w', encoding='utf-8') as f:\n","      json.dump(tickers, f, ensure_ascii=False, indent=4)\n","  print(f'{status} tickers have been logged to {status} tickers list')\n","  return\n","\n","logs_filepath = '/p2outputs/logs'\n","log_availability_of_tickers_to_json(tickers_avaliable_on_yf, logs_filepath, status='avaliable')\n","log_availability_of_tickers_to_json(tickers_not_avaliable_on_yf, logs_filepath, status='missing')"],"metadata":{"id":"ZTudJ3dwYqqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here you can choose which format you want to save your historicals as\n","# You can use pd.hdfstore to store your historicals in a pandas format but it will require different formatting. \n","# Currently hdf5 are saved to accommodate loading as numpys\n","# Dividends and stock splits are removed, because we have already included for them\n","# when we downloaded the auto adjusted OHLC data from Yahoo Finance. \n","\n","def format_historicals_to_save_as_csv(historicals):\n","  '''Formats historicals to safely save as csv files.\n","\n","  Args:\n","    historicals: dict with tickers as keys and OHLC data as values.\n","                 Each OHLC data is given as a pandas dataframe. \n","\n","  Returns:\n","    csv_historicals: formatted historicals to save as csv files\n","  '''\n","\n","  csv_historicals = {}\n","\n","  for ticker in historicals:\n","    csv_historicals[ticker] = historicals[ticker].drop(['Dividends', 'Stock Splits'], axis='columns')\n","    csv_historicals[ticker] = csv_historicals[ticker].reset_index()\n","  print('Finished formatting historicals as csv format')\n","  return csv_historicals\n","\n","def format_historicals_to_save_as_hdf5(historicals):\n","  '''Formats historicals to safely save as hdf5 files.\n","\n","  Args:\n","    historicals: dict with tickers as keys and OHLC data as values.\n","                 Each OHLC data is given as a pandas dataframe. \n","\n","  Returns:\n","    historicals: formatted historicals to save as hdf5 files\n","  '''\n","\n","  hdf5_historicals = {}\n","\n","  for ticker in historicals:\n","    hdf5_historicals[ticker] = historicals[ticker].drop(['Dividends', 'Stock Splits'], axis='columns')\n","    hdf5_historicals[ticker] = hdf5_historicals[ticker].reset_index()\n","    hdf5_historicals[ticker]['Date'] = hdf5_historicals[ticker]['Date'].apply(lambda x: x.timestamp())\n","  print('Finished formatting historicals as hdf5 format')\n","  return hdf5_historicals\n","\n","hdf5_historicals = format_historicals_to_hdf5(historicals)"],"metadata":{"id":"vzGIFqTuW0IS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643336780875,"user_tz":420,"elapsed":13,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"outputId":"07c66990-3423-4eb9-b09f-6a3077d590b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished formatting historicals as hdf5 format\n"]}]},{"cell_type":"code","source":["# Save your historicals to a filepath of your choice\n","\n","def save_historicals_to_csv(historicals, filepath):\n","  '''Save historicals as csv files.'''\n","  for ticker in historicals:\n","    csv_filepath = f'{filepath}/{ticker}.csv'\n","    historicals[ticker].to_csv(csv_filepath)\n","    print(f'Ticker {ticker} Saved as CSV')\n","  print('All Tickers Have Been Saved')\n","\n","def save_historicals_to_hdf5(historicals, filepath):\n","  '''Saves historicals as hdf5 files.'''\n","  for ticker in historicals:\n","    hdf5_filepath = f'{filepath}/{ticker}.hdf5'\n","    with h5py.File(hdf5_filepath, 'w') as f:\n","      history = f.create_group('historicals')\n","      history.create_dataset(name='15Y',\n","                             data=historicals[ticker],\n","                             maxshape=(None, 6),  # Specify a maxshape of None in the row axis so future dates can be added on the rows\n","                             compression='gzip')\n","    print(f'Saved {ticker} as HDF5')\n","\n","historicals_filepath = '/p2outputs'\n","save_historicals_to_hdf5(hdf5_historicals, historicals_filepath)"],"metadata":{"id":"rBv2YmScVD6K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643336988950,"user_tz":420,"elapsed":244,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"outputId":"4264554b-4ab4-439c-a517-971c1f9bb29f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved AAPL as HDF5\n"]}]},{"cell_type":"code","source":["# Check if all the tickers were saved succesfully as the file format of your choice, please specifiy in the 'save_type' keyword\n","\n","def check_if_tickers_were_saved_successfully(tickers, filepath, save_type='hdf5'):\n","  '''Checks if the tickers were saved successfully as their specified save type.\n","\n","  Args:\n","    tickers: list containing each ticker given as a string.\n","    filepath: string of where the historicals are saved.\n","    save_type: string that checks if the tickers were saved in the\n","               specifed type. Options are {'hdf5', 'csv'}.\n","               Defaults to 'hdf5'.\n","\n","  Returns:\n","    tickers_not_saved: list containing the tickers\n","                       that were not saved successfully.\n","\n","  Raises:\n","    AssertionError: Save type must be \"csv\" or \"hdf5\"\n","  '''\n","\n","  assert save_type in ['csv', 'hdf5'], 'Save type must be \"csv\" or \"hdf5\"'\n","\n","  tickers_not_saved = []\n","\n","  for ticker in tickers:\n","    ticker_filepath = f'{filepath}/{ticker}.{save_type}'\n","    ticker_file = Path(ticker_filepath)\n","    if ticker_file.is_file():\n","      pass\n","    else:\n","      print(f\"{ticker} is missing\")\n","      tickers_not_saved.append(ticker)\n","  return tickers_not_saved\n","\n","tickers_not_saved = check_if_tickers_saved_successfully(tickers_avaliable_on_yf, historicals_filepath)\n","print(f'Tickers NOT saved successfully were {tickers_not_saved}')"],"metadata":{"id":"8VyfjGzlaNgP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642642554852,"user_tz":420,"elapsed":307,"user":{"displayName":"Robbie Lem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00925855096223384832"}},"outputId":"cff0a387-052d-48af-fc7f-d6e5a36c4f17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tickers NOT saved successfully were []\n"]}]},{"cell_type":"markdown","source":["## For Reference: How to load your database to memory"],"metadata":{"id":"z3B-AImcjGH1"}},{"cell_type":"code","source":["# For reference on how to load your database as a pandas dataframe, you will need your sp500_constituents list\n","# There is no need to run this if you are still downloading all your historicals from Yahoo Finance\n","\n","def load_csv_historicals(tickers, filepath):\n","  '''Load csv historicals to memory.\n","\n","  Args:\n","    tickers: list containing each ticker given as a string.\n","    filepath: string of where the historicals are saved.\n","\n","  Returns:\n","    historicals: dict with tickers as keys and OHLC data as values.\n","                 Each OHLC data is given as a pandas dataframe. \n","  '''\n","\n","  historicals = dict()\n","\n","  for ticker in tickers:\n","    csv_filepath = f'{filepath}/{ticker}.csv'\n","    ticker_file = Path(csv_filepath)\n","    if ticker_file.is_file():\n","      dataset = pd.read_csv(csv_filepath, index_col='Date')\n","      historicals[ticker] = dataset\n","    else:\n","      print(f'Error {ticker} ticker is missing')\n","  return historicals\n","\n","def load_hdf5_historicals(tickers, filepath):\n","  '''Load hdf5 historicals to memory.\n","\n","  Args:\n","    tickers: list containing each ticker given as a string.\n","    filepath: string of where the historicals are saved.\n","\n","  Returns:\n","    historicals: dict with tickers as keys and OHLC data as values.\n","                 Each OHLC data is given as a pandas dataframe. \n","  '''\n","\n","  historicals = dict()\n","  columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n","  \n","  for ticker in tickers:\n","    hdf5_filepath = f'{filepath}/{ticker}.hdf5'\n","    ticker_file = Path(hdf5_filepath)\n","    if ticker_file.is_file():\n","      with h5py.File(hdf5_filepath, 'r') as f:\n","        group = f['historicals']\n","        data = group['15Y'][()]\n","      \n","      dataset = pd.DataFrame(data=data, columns=columns)\n","      dataset['Date'] = pd.to_datetime(dataset['Date'], unit='s')\n","      dataset = dataset.set_index('Date')\n","      historicals[ticker] = dataset\n","    else:\n","      print(f'Error {ticker} ticker is missing')\n","    print('All Historicals Have Been Saved to Memory')\n","  return historicals\n","\n","historicals = load_hdf5_historicals(sp500_constituents, historicals_filepath)"],"metadata":{"id":"PCgJggrq4Bf2"},"execution_count":null,"outputs":[]}]}